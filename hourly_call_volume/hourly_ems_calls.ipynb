{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the framework for doing the batch transform for hourly call volume predictions using NFORS data. The cells at the beginning of the notebook are all required for running the code, but the end of the notebook contains the code I used for creating the datasets for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If running in local mode, local to True. Otherwise, set it to false\n",
    "# local = False\n",
    "local = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Sagemaker role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# S3 prefix\n",
    "prefix = 'hourly_call_volume'\n",
    "\n",
    "\n",
    "if local == True:\n",
    "    sagemaker_session = sagemaker.LocalSession()\n",
    "    role = 'arn:aws:iam::445861113736:role/service-role/AmazonSageMaker-ExecutionRole-20190903T114521'\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator <a class=\"anchor\" id=\"create_sklearn_estimator\"></a>\n",
    "\n",
    "To run our Scikit-learn training script on SageMaker, we construct a `sagemaker.sklearn.estimator.sklearn` estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training. __Note__: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "* __hyperparameters__ *(optional)*: A dictionary passed to the train function as hyperparameters.\n",
    "\n",
    "To see the code for the SKLearn Estimator, see here: https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "script_path = 'hourly_call_prediction.py'\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={'n_estimators': 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SKLearn Estimator on call volume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpr8a_8veh_algo-1-4phej_1 ... \n",
      "\u001b[1BAttaching to tmpr8a_8veh_algo-1-4phej_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:19,875 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:19,880 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:19,900 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:20,225 sagemaker-containers INFO     Module hourly_call_prediction does not provide a setup.py. \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:20,225 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:20,225 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:20,226 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Building wheels for collected packages: hourly-call-prediction\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m   Building wheel for hourly-call-prediction (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \u001b[?25h  Created wheel for hourly-call-prediction: filename=hourly_call_prediction-1.0.0-py2.py3-none-any.whl size=7375 sha256=848b79597a4f54e4d416e1b0f843e0812dbace46721963453cded32990d4ca44\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-q_51bp1t/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Successfully built hourly-call-prediction\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Installing collected packages: hourly-call-prediction\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Successfully installed hourly-call-prediction-1.0.0\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:21,552 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:54:21,564 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"current_host\": \"algo-1-4phej\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         \"algo-1-4phej\"\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         \"n_estimators\": 1000\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2020-01-22-16-54-16-762\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"master_hostname\": \"algo-1-4phej\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-2-445861113736/sagemaker-scikit-learn-2020-01-22-16-54-16-762/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"module_name\": \"hourly_call_prediction\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         \"current_host\": \"algo-1-4phej\",\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m             \"algo-1-4phej\"\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m     \"user_entry_point\": \"hourly_call_prediction.py\"\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_HOSTS=[\"algo-1-4phej\"]\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_HPS={\"n_estimators\":1000}\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_USER_ENTRY_POINT=hourly_call_prediction.py\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-4phej\",\"hosts\":[\"algo-1-4phej\"]}\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_CURRENT_HOST=algo-1-4phej\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_MODULE_NAME=hourly_call_prediction\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-2-445861113736/sagemaker-scikit-learn-2020-01-22-16-54-16-762/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-4phej\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-4phej\"],\"hyperparameters\":{\"n_estimators\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-01-22-16-54-16-762\",\"log_level\":20,\"master_hostname\":\"algo-1-4phej\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-445861113736/sagemaker-scikit-learn-2020-01-22-16-54-16-762/source/sourcedir.tar.gz\",\"module_name\":\"hourly_call_prediction\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-4phej\",\"hosts\":[\"algo-1-4phej\"]},\"user_entry_point\":\"hourly_call_prediction.py\"}\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_USER_ARGS=[\"--n_estimators\",\"1000\"]\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m SM_HP_N_ESTIMATORS=1000\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m PYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m /miniconda3/bin/python -m hourly_call_prediction --n_estimators 1000\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m \n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-4phej_1  |\u001b[0m 2020-01-22 16:55:33,098 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmpr8a_8veh_algo-1-4phej_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "#The data should already be saved to the ./data directory\n",
    "WORK_DIRECTORY = 'data'\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY) )\n",
    "\n",
    "#Training the model\n",
    "sklearn.fit({'train': train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform <a class=\"anchor\" id=\"batch_transform\"></a>\n",
    "We can also use the trained model for asynchronous batch inference on S3 data using SageMaker Batch Transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Transform Job <a class=\"anchor\" id=\"run_transform_job\"></a>\n",
    "Using the Transformer, run a transform job on the S3 input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpf2v8y628_algo-1-6lmtb_1\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m Building wheels for collected packages: hourly-call-prediction\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m   Building wheel for hourly-call-prediction (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m \u001b[?25h  Created wheel for hourly-call-prediction: filename=hourly_call_prediction-1.0.0-py2.py3-none-any.whl size=7376 sha256=1c97c7c5221e67b131dfe666c1dc0b718835d17cb37ebf6628bbe35cdd4e339c\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-olfsomla/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m Successfully built hourly-call-prediction\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m Installing collected packages: hourly-call-prediction\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m Successfully installed hourly-call-prediction-1.0.0\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [217] [INFO] Starting gunicorn 19.9.0\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [217] [INFO] Listening at: unix:/tmp/gunicorn.sock (217)\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [217] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [220] [INFO] Booting worker with pid: 220\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [284] [INFO] Booting worker with pid: 284\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [285] [INFO] Booting worker with pid: 285\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:05 +0000] [286] [INFO] Booting worker with pid: 286\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [413] [INFO] Booting worker with pid: 413\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [477] [INFO] Booting worker with pid: 477\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [541] [INFO] Booting worker with pid: 541\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [542] [INFO] Booting worker with pid: 542\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [543] [INFO] Booting worker with pid: 543\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [544] [INFO] Booting worker with pid: 544\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [734] [INFO] Booting worker with pid: 734\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [798] [INFO] Booting worker with pid: 798\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [925] [INFO] Booting worker with pid: 925\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [927] [INFO] Booting worker with pid: 927\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [928] [INFO] Booting worker with pid: 928\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1119] [INFO] Booting worker with pid: 1119\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1185] [INFO] Booting worker with pid: 1185\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1188] [INFO] Booting worker with pid: 1188\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1317] [INFO] Booting worker with pid: 1317\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1381] [INFO] Booting worker with pid: 1381\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1383] [INFO] Booting worker with pid: 1383\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1448] [INFO] Booting worker with pid: 1448\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1449] [INFO] Booting worker with pid: 1449\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:06 +0000] [1513] [INFO] Booting worker with pid: 1513\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1579] [INFO] Booting worker with pid: 1579\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1770] [INFO] Booting worker with pid: 1770\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1771] [INFO] Booting worker with pid: 1771\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m 2020-01-22 17:27:07,089 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1773] [INFO] Booting worker with pid: 1773\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1774] [INFO] Booting worker with pid: 1774\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1777] [INFO] Booting worker with pid: 1777\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1841] [INFO] Booting worker with pid: 1841\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [1969] [INFO] Booting worker with pid: 1969\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2160] [INFO] Booting worker with pid: 2160\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2225] [INFO] Booting worker with pid: 2225\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2289] [INFO] Booting worker with pid: 2289\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2353] [INFO] Booting worker with pid: 2353\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2354] [INFO] Booting worker with pid: 2354\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2356] [INFO] Booting worker with pid: 2356\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2357] [INFO] Booting worker with pid: 2357\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2422] [INFO] Booting worker with pid: 2422\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2553] [INFO] Booting worker with pid: 2553\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2871] [INFO] Booting worker with pid: 2871\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2872] [INFO] Booting worker with pid: 2872\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [2937] [INFO] Booting worker with pid: 2937\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [3066] [INFO] Booting worker with pid: 3066\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [3070] [INFO] Booting worker with pid: 3070\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [3134] [INFO] Booting worker with pid: 3134\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:07 +0000] [3136] [INFO] Booting worker with pid: 3136\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3200] [INFO] Booting worker with pid: 3200\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3391] [INFO] Booting worker with pid: 3391\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3393] [INFO] Booting worker with pid: 3393\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3396] [INFO] Booting worker with pid: 3396\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3398] [INFO] Booting worker with pid: 3398\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m 172.18.0.1 - - [22/Jan/2020:17:27:08 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3528] [INFO] Booting worker with pid: 3528\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m 2020-01-22 17:27:08,288 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3593] [INFO] Booting worker with pid: 3593\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3657] [INFO] Booting worker with pid: 3657\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3659] [INFO] Booting worker with pid: 3659\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3724] [INFO] Booting worker with pid: 3724\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3726] [INFO] Booting worker with pid: 3726\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3854] [INFO] Booting worker with pid: 3854\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [3981] [INFO] Booting worker with pid: 3981\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [4045] [INFO] Booting worker with pid: 4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [4146] [INFO] Booting worker with pid: 4146\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m [2020-01-22 17:27:08 +0000] [4301] [INFO] Booting worker with pid: 4301\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m 172.18.0.1 - - [22/Jan/2020:17:27:09 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"-\"\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m 2020-01-22 17:27:09,775 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-6lmtb_1  |\u001b[0m 172.18.0.1 - - [22/Jan/2020:17:27:10 +0000] \"POST /invocations HTTP/1.1\" 200 6663 \"-\" \"-\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Waiting for transform job: sagemaker-scikit-learn-2020-01-22-17-26-59-165\n",
      "."
     ]
    }
   ],
   "source": [
    "#Again, the test data should already be saved to the prediction_data directory\n",
    "WORK_DIRECTORY = 'prediction_data'\n",
    "batch_input_s3 = sagemaker_session.upload_data(WORK_DIRECTORY, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY) )\n",
    "\n",
    "# Start a transform job and wait for it to finish\n",
    "transformer.transform(batch_input_s3, content_type='application/json')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'batch_data/output/*' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Download the output data from S3 to local filesystem\n",
    "batch_output = transformer.output_path\n",
    "!mkdir -p batch_data/output\n",
    "!aws s3 cp --recursive $batch_output/ batch_data/output/\n",
    "# Head to see what the batch output looks like\n",
    "!head batch_data/output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-445861113736/sagemaker-scikit-learn-2020-01-22-17-26-59-165'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_current_job_name',\n",
       " '_ensure_last_transform_job',\n",
       " '_prepare_init_params_from_job_description',\n",
       " '_reset_output_path',\n",
       " '_retrieve_base_name',\n",
       " '_retrieve_image_name',\n",
       " 'accept',\n",
       " 'assemble_with',\n",
       " 'attach',\n",
       " 'base_transform_job_name',\n",
       " 'delete_model',\n",
       " 'env',\n",
       " 'instance_count',\n",
       " 'instance_type',\n",
       " 'latest_transform_job',\n",
       " 'max_concurrent_transforms',\n",
       " 'max_payload',\n",
       " 'model_name',\n",
       " 'output_kms_key',\n",
       " 'output_path',\n",
       " 'sagemaker_session',\n",
       " 'stop_transform_job',\n",
       " 'strategy',\n",
       " 'tags',\n",
       " 'transform',\n",
       " 'volume_kms_key',\n",
       " 'wait']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-96c3c8ac702f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./prediction_data/test_data.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "data = json.loads('./prediction_data/test_data.json')\n",
    "df = pd.io.json.json_normalize(data['prediction_data'])\n",
    "features = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Output Data  <a class=\"anchor\" id=\"check_output_data\"></a>\n",
    "After the transform job has completed, download the output data from S3. For each file \"f\" in the input data, we have a corresponding file \"f.out\" containing the predicted labels from each input row. We can compare the predicted labels to the true labels saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.262, 13.651, 13.776, 64.899, 32.359, 80.751, 119.24432222222221, 67.791, 14.291, 9.6, 77.111, 11.977, 71.26, 17.555, 76.62, 71.955, 65.988, 69.633, 72.4, 67.801, 16.868, 15.341, 14.491, 68.154, 73.672, 13.88, 11.946, 94.801953968254, 30.46, 76.214, 12.099, 32.963, 111.37256608946599, 75.409, 13.584, 10.49, 13.494, 14.924, 20.175, 13.632, 11.323, 79.148, 13.037, 13.741, 71.156, 12.984, 13.376, 71.529, 13.335, 14.749, 63.824, 73.622, 13.242, 10.425, 14.079, 70.725, 35.103, 14.916, 68.318, 16.027, 13.933, 13.86, 15.153, 61.511, 12.992, 69.234, 69.987, 13.4, 65.712, 11.144, 73.905, 63.855, 78.564, 69.216, 10.006, 12.519, 34.603, 65.763, 78.152, 13.837, 87.715, 13.497, 69.304, 68.77, 13.061, 69.625, 11.177, 9.125, 73.762, 69.42, 68.098, 70.547, 66.93, 16.691, 69.59, 16.193, 12.927, 73.688, 65.495, 72.673, 74.601, 66.103, 78.257, 14.602, 77.926, 12.563, 11.194, 73.189, 13.907, 64.898, 78.776, 86.40980952380953, 74.366, 33.019, 9.718, 9.49, 75.839, 12.261, 14.203, 77.327, 13.315, 14.497, 10.363, 106.61329285714305, 74.848, 71.418, 73.904, 80.499, 10.952, 34.172, 9.84, 15.954, 82.723, 68.645, 13.707, 66.998, 13.093, 73.693, 11.446, 34.867, 70.483, 81.997, 66.657, 68.591, 71.718, 83.028, 87.985, 75.177, 68.816, 78.751, 67.674, 14.53, 14.584, 10.709, 67.433, 64.054, 68.744, 12.735, 68.651, 72.595, 73.207, 76.443, 68.709, 87.266, 9.372, 12.915, 13.765, 68.825, 32.829, 75.886, 12.89, 79.234, 33.572, 94.801953968254, 12.178, 29.611, 14.85, 74.366, 34.057, 15.214, 72.201, 69.634, 73.877, 15.388, 78.361, 74.289, 80.711, 13.029, 15.583, 70.212, 72.791, 11.122, 67.854, 76.387, 73.813, 77.439, 65.774, 10.246, 70.459, 69.825, 68.103, 12.831, 13.49, 66.907, 75.996, 12.392, 74.366, 75.152, 13.795, 64.088, 13.661, 73.69385357142858, 33.164, 82.827, 72.102, 70.941, 72.143, 71.488, 13.863, 70.82, 12.435, 73.983, 66.787, 14.16, 29.337, 70.492, 76.39, 15.87, 74.796, 10.067, 73.073, 14.775, 66.981, 67.305, 13.277, 76.176, 12.369, 12.013, 15.519, 35.281, 13.843, 10.792, 68.624, 66.955, 75.262, 12.093, 11.282, 13.05, 90.98998928571427, 37.094, 70.013, 69.106, 10.854, 74.081, 13.546, 14.392, 10.308, 68.206, 33.916, 15.178, 10.041, 14.332, 11.898, 68.216, 75.743, 31.311, 71.281, 10.041, 74.526, 73.69385357142858, 13.828, 68.403, 92.08649404761906, 14.93, 70.543, 65.311, 73.618, 13.645, 77.125, 31.935, 13.194, 72.985, 73.628, 36.836, 13.945, 11.404, 71.579, 72.246, 68.684, 11.822, 98.12545079365086, 10.565, 14.766, 10.606, 64.758, 71.565, 15.454, 11.505, 13.314, 76.84, 14.442, 14.896, 12.38, 73.341, 14.098, 10.145, 71.308, 75.574, 73.551, 78.7, 16.722, 66.284, 72.214, 33.145, 14.022, 69.344, 13.671, 10.329, 32.378, 74.6, 63.302, 12.392, 68.751, 17.76, 70.814, 66.432, 35.414, 76.208, 36.409, 77.563, 73.725, 33.859, 68.424, 77.488, 12.777, 16.565, 16.226, 73.936, 12.871, 13.205, 73.318, 34.691, 35.696, 10.445, 68.256, 70.629, 13.837, 74.657, 86.40980952380953, 16.206, 63.366, 66.724, 11.669, 66.012, 68.393, 71.26, 14.463, 73.289, 75.592]"
     ]
    }
   ],
   "source": [
    "# Download the output data from S3 to local filesystem\n",
    "batch_output = transformer.output_path\n",
    "!mkdir -p batch_data/output\n",
    "!aws s3 cp --recursive $batch_output/ batch_data/output/\n",
    "# Head to see what the batch output looks like\n",
    "!head batch_data/output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling the predictions, comparing to the observed number of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "output_loc = './batch_data/output/test_data.json.out'\n",
    "\n",
    "with open (output_loc, \"r\") as myfile:\n",
    "    data=myfile.readlines()\n",
    "    \n",
    "string_output = data[0].replace('[','').replace(']','')\n",
    "\n",
    "predicted = np.genfromtxt(StringIO(string_output),delimiter=',')\n",
    "actual = np.genfromtxt('observed',delimiter=',')[1:,1]\n",
    "plt.scatter(predicted,actual,alpha=0.3)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the training data and uploading to s3\n",
    "This cell only works locally because it depends on elasticsearch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries required for performing the query\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "from elasticsearch_dsl import Q\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#Setting up the query\n",
    "es = Elasticsearch()\n",
    "s = Search(using=es,index='*-fire-incident-*')\n",
    "s = s.source(['description.event_opened',\n",
    "                     'description.day_of_week',\n",
    "                    'NFPA.type',\n",
    "                     'fire_department.firecares_id'])\n",
    "\n",
    "\n",
    "#Performing the query\n",
    "q = Q(\"match\",fire_department__firecares_id =  '79592') | Q(\"match\",fire_department__firecares_id =  '93345')\n",
    "results = s.query(q)\n",
    "\n",
    "#Converting query results to a pandas dataframe\n",
    "df = pd.DataFrame((d.to_dict() for d in tqdm_notebook(results.scan())))\n",
    "json_struct = json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "df = pd.io.json.json_normalize(json_struct)\n",
    "\n",
    "#Converting date\n",
    "df['date'] = df['description.event_opened'].apply(lambda x: x[:10])\n",
    "df['month'] = df.apply(lambda x: x['date'][5:7], axis=1)\n",
    "df['hour'] = df['description.event_opened'].apply(lambda x: x[11:13])\n",
    "\n",
    "\n",
    "#Converting df dates to datetime objects\n",
    "df['date'] = df.apply(lambda x: datetime.datetime.strptime(x['date'],'%Y-%m-%d'),axis=1)\n",
    "# df['date'] = df.apply(lambda x: datetime.datetime.strptime(x['date'],'%Y-%m-%d'),axis=1)\n",
    "\n",
    "#It's convenient to serialize (pickle) the dataframe because it's faster to load it rather than re-create it.\n",
    "df.to_pickle('query_results')\n",
    "\n",
    "#Hourly is a dataframe aggregated grouped by the day, hour, and department\n",
    "hourly = df[['fire_department.firecares_id', 'date','description.day_of_week', 'hour']].groupby(['fire_department.firecares_id', 'date','description.day_of_week', 'hour']).aggregate(len).reset_index()\n",
    "hourly = hourly.rename(columns={0: 'calls'})\n",
    "\n",
    "#Formatting the hourly dataframe into a json\n",
    "jsondata = {}\n",
    "jsondata['model_name'] = 'calls_by_hour'\n",
    "jsondata['model_version'] = 1.0\n",
    "jsondata['prediction_data'] = hourly.drop('date',axis=1).to_dict(orient='records')\n",
    "\n",
    "#Saving the json to the data directory\n",
    "with open('./data/training_data.json', 'w') as outfile:\n",
    "    json.dump(jsondata, outfile)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the test dataset\n",
    "This involves generating a dataframe with every possible combination of department, day of week, and hour of the day. The size of this dataset is 7x24xn, where n is the number of departments included for predictions.\n",
    "\n",
    "Also, this cell requires that the training set has already been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make every combination of departments, days of week, and hour\n",
    "from itertools import product\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#load the training dataset\n",
    "with open('./data/training_data.json') as data_file:\n",
    "    data = json.load(data_file)\n",
    "hourly = pd.io.json.json_normalize(data['prediction_data'])\n",
    "\n",
    "#Getting the list of ever department that shows up in the hourly dataframe\n",
    "dep_list = hourly['fire_department.firecares_id'].unique()\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hours = [str(i) for i in range(24)]\n",
    "\n",
    "#Creating the dataframe of all possible combinations\n",
    "test_df = pd.DataFrame(list(product(dep_list, days, hours)), columns=['fire_department.firecares_id', 'description.day_of_week', 'hour'])\n",
    "\n",
    "#Formatting it as a json\n",
    "jsondata = {}\n",
    "jsondata['model_name'] = 'calls_by_hour'\n",
    "jsondata['model_version'] = 1.0\n",
    "jsondata['prediction_data'] = test_df.to_dict(orient='records')\n",
    "\n",
    "#Saving it locally\n",
    "with open('./prediction_data/test_data.json', 'w') as outfile:\n",
    "    json.dump(jsondata, outfile)\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
