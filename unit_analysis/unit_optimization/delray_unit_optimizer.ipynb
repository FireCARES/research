{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit_decision import *\n",
    "\n",
    "#Delray Beach, FL\n",
    "fdid = '06172'\n",
    "state = 'FL'\n",
    "firecares_id = '79592'\n",
    "\n",
    "#Note I lumped both engines and Truck/Aerial into one category called \"Suppression\"\n",
    "unit_type_mapping = {'ALS':['ALS'], 'Suppression':['Engine','Truck/Aerial']}\n",
    "\n",
    "#Exclude stations\n",
    "exclude_stations = ['116']\n",
    "\n",
    "#Specifiying units to ignore\n",
    "bad_units = ['EMS111', 'R2111']\n",
    "\n",
    "#Specifying fields that must not contain NaNs\n",
    "drop_subset=['address.first_due','unit_status.dispatched.timestamp','unit_status.available.timestamp']\n",
    "\n",
    "#Creating a department object and loading methods to populate its fields\n",
    "dep = department(firecares_id,fdid,state,load_all=True,unit_type_mapping=unit_type_mapping,bad_units=bad_units, exclude_stations=exclude_stations)\n",
    "dep.cleaner(drop_subset)\n",
    "dep.from_station()\n",
    "dep.first_due_analysis()\n",
    "dep.station_builder()\n",
    "\n",
    "#Don't worry too much about this. I tried several distribution fitting approaches for the DA class\n",
    "p = (10,50,90)\n",
    "weights = (0.3,0.4,0.3)\n",
    "dep.build_distribution(p,weights)\n",
    "dep.build_lognorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.df.unit_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for optimization tool\n",
    "dep.optimizer('Suppression', 2, dep.quantile)\n",
    "print(dep.best) #prints the list of stations that should get new units\n",
    "print(dep.improvement) #Prints the expected improvement (in seconds) to global response time distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.optimizer('Suppression', 2)\n",
    "print(dep.best)\n",
    "print(dep.improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [6,4]\n",
    "als = dep.df[dep.df['unit_type'] == 'ALS'].reset_index(drop=True)\n",
    "from_due = np.array(als[als['from_first_due']==True]['extended_data.response_duration'])/60\n",
    "not_from_due = np.array(als[als['from_first_due']==False]['extended_data.response_duration'])/60\n",
    "\n",
    "percentiles = np.arange(100)\n",
    "plt.plot(np.percentile(from_due, percentiles),percentiles, color='dodgerblue', linewidth=4)\n",
    "plt.plot(np.percentile(not_from_due, percentiles),percentiles, color='orangered', linewidth=4)\n",
    "plt.xlabel('Response time (min)')\n",
    "plt.ylabel('Percentile')\n",
    "plt.yticks(np.linspace(0,100,11))\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([0,16])\n",
    "plt.legend(['From first due', 'Not from first due'])\n",
    "plt.savefig('dep_cdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.station_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_type = 'ALS'\n",
    "\n",
    "\n",
    "alias = [str(i) for i in range(111,118)]\n",
    "\n",
    "q = np.arange(100)\n",
    "plt.rcParams['figure.figsize'] = [12,12]\n",
    "for i,station_num in enumerate(dep.station_list):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    send = dep.station_dict[station_num].sent_full[unit_type]\n",
    "    nsend = dep.station_dict[station_num].not_sent_full[unit_type]\n",
    "    \n",
    "    print(str(np.floor(np.mean(send)/60))+':'  + str(np.mean(send)%60)  )\n",
    "    print(str(np.floor(np.mean(nsend)/60))+':' + str(np.mean(nsend)%60) )\n",
    "    \n",
    "    plt.plot(np.percentile(send,q),q, color='dodgerblue',linewidth=2)\n",
    "    plt.plot(np.percentile(nsend,q),q, color='orangered',linewidth=2)\n",
    "    plt.xlabel('Response time (min)')\n",
    "    plt.ylabel('Percentile')\n",
    "    plt.title('First due area of Station '+ alias[i])\n",
    "    plt.xlim([0,16])\n",
    "    plt.ylim([0,100])\n",
    "    plt.tight_layout()\n",
    "    plt.legend(['From first due', 'Not from first due' ])\n",
    "    \n",
    "    plt.savefig('station_cdfs')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_type = 'Suppression'\n",
    "\n",
    "\n",
    "alias = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "q = np.arange(100)\n",
    "plt.rcParams['figure.figsize'] = [12,8]\n",
    "for i,station_num in enumerate(dep.station_list):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    send = dep.station_dict[station_num].sent_full[unit_type]\n",
    "    nsend = dep.station_dict[station_num].not_sent_full[unit_type]\n",
    "    print(np.mean(send))\n",
    "    print(np.mean(nsend))\n",
    "    \n",
    "    plt.plot(np.percentile(send,q),q, color='dodgerblue',linewidth=2)\n",
    "    plt.plot(np.percentile(nsend,q),q, color='orangered',linewidth=2)\n",
    "    plt.xlabel('Response time (s)')\n",
    "    plt.ylabel('Percentile')\n",
    "    plt.title('Station '+ alias[i])\n",
    "    plt.xlim([0,1000])\n",
    "    plt.ylim([0,100])\n",
    "    plt.tight_layout()\n",
    "    plt.legend(['From first due', 'Not from first due' ])\n",
    "    \n",
    "#     plt.savefig(figloc+'firediff')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndue = als[als['from_first_due']==False].reset_index(drop=True)\n",
    "np.sum(ndue['num_required']>1)/len(ndue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ndue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.df['num_active'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figloc = './DA_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snum = '116'\n",
    "df = dep.station_dict[snum].df\n",
    "df = df[df['unit_type']=='Suppression']\n",
    "no_units = df[df['num_active'] == 0]\n",
    "np.sum(no_units['station']==snum)/len(no_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.station_dict[station_num].num_required[unit_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,6]\n",
    "unit_type = 'ALS'\n",
    "\n",
    "for j,station_num in enumerate(dep.station_list):\n",
    "    plt.subplot(2,3,j+1)\n",
    "    vals = np.arange(1,len(dep.station_dict[station_num].num_required[unit_type])+1)\n",
    "    vals= [str(i) for i in vals]\n",
    "    plt.bar(vals,dep.station_dict[station_num].num_required[unit_type])\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('Number of units required to dispatch additional')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Station '+ alias[j])\n",
    "    plt.tight_layout()\n",
    "plt.savefig(figloc+'alsbar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,6]\n",
    "unit_type = 'Suppression'\n",
    "\n",
    "for j,station_num in enumerate(dep.station_list):\n",
    "    plt.subplot(2,3,j+1)\n",
    "    vals = np.arange(1,len(dep.station_dict[station_num].num_required[unit_type])+1)\n",
    "    vals= [str(i) for i in vals]\n",
    "    plt.bar(vals,dep.station_dict[station_num].num_required[unit_type])\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlabel('Number of units required to dispatch additional')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Station '+ alias[j])\n",
    "    plt.tight_layout()\n",
    "plt.savefig(figloc+'firebar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.optimizer('ALS', 2, dep.mean_calc)\n",
    "dep.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.first_due_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_type = 'ALS'\n",
    "for i, station_num in enumerate(dep.station_list):\n",
    "    print(dep.station_dict[station_num].send_given_available)\n",
    "#     print(dep.station_dict[station_num].send_probs[unit_type]/dep.station_dict[station_num].first_due_probs[unit_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.station_dict['116'].send_given_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.df[dep.df['unit_type']=='Truck/Aerial']['unit_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lognormal fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,4]\n",
    "for i,unit_type in enumerate(dep.unit_types):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    x = np.linspace(1,1200)\n",
    "\n",
    "    plt.plot(x,dep.lognorm[unit_type].cdf(x)*100, color='dodgerblue', linewidth=5, alpha=0.5)\n",
    "    q = np.arange(100)\n",
    "    real_times = np.percentile(dep.df[dep.df['unit_type'] == unit_type]['extended_data.response_duration'],q)\n",
    "    plt.plot(real_times,q,color='orangered',linewidth=5, alpha=0.5)\n",
    "\n",
    "    plt.legend(['Log-normal fit', 'Actual data'])\n",
    "    plt.title(unit_type +' unit responses')\n",
    "    plt.xlabel('Response time (sec)')\n",
    "    plt.ylabel('Percentile')\n",
    "    \n",
    "    \n",
    "plt.savefig(figloc+'lognorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,4]\n",
    "for i,unit_type in enumerate(dep.unit_types):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    x = np.linspace(1,1200)\n",
    "    idx = np.argsort(dep.times[unit_type])\n",
    "    times = dep.times[unit_type][idx]\n",
    "    probs = dep.probs[unit_type][idx]\n",
    "    cum_prob = np.cumsum(probs)\n",
    "    \n",
    "    plt.plot(times,cum_prob*100, color='dodgerblue', linewidth=5, alpha=0.5)\n",
    "    q = np.arange(100)\n",
    "    real_times = np.percentile(dep.df[dep.df['unit_type'] == unit_type]['extended_data.response_duration'],q)\n",
    "    plt.plot(real_times,q,color='orangered',linewidth=5, alpha=0.5)\n",
    "\n",
    "    plt.legend(['Swanson mean ', 'Actual data'])\n",
    "    plt.xlabel('Response time (sec)')\n",
    "    plt.ylabel('Percentile')\n",
    "    plt.title(unit_type +' unit responses')\n",
    "\n",
    "    \n",
    "plt.savefig(figloc+'swanson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (10,50,90)\n",
    "weights = (0.3,0.4,0.3)\n",
    "dep.build_distribution(p,weights)\n",
    "plt.rcParams['figure.figsize'] = [12,4]\n",
    "for i,unit_type in enumerate(dep.unit_types):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    x = np.linspace(1,1200)\n",
    "    idx = np.argsort(dep.times[unit_type])\n",
    "    times = dep.times[unit_type][idx]\n",
    "    probs = dep.probs[unit_type][idx]\n",
    "    cum_prob = np.cumsum(probs)\n",
    "    \n",
    "    plt.plot(times,cum_prob*100, color='dodgerblue', linewidth=5, alpha=0.5)\n",
    "    q = np.arange(100)\n",
    "    real_times = np.percentile(dep.df[dep.df['unit_type'] == unit_type]['extended_data.response_duration'],q)\n",
    "    plt.plot(real_times,q,color='orangered',linewidth=5, alpha=0.5)\n",
    "\n",
    "    plt.legend(['Swanson mean ', 'Actual data'])\n",
    "    plt.title(unit_type +' unit responses')\n",
    "    plt.xlabel('Response time (sec)')\n",
    "    plt.ylabel('Percentile')\n",
    "    \n",
    "plt.savefig(figloc+'swanson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep.monte_carlo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12,4]\n",
    "for i,unit_type in enumerate(dep.unit_types):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    x = np.linspace(1,1200)\n",
    "    q = np.arange(100)\n",
    "    mc_times = np.percentile(dep.mc_times[unit_type],q)\n",
    "    plt.plot(mc_times,q, color='dodgerblue', linewidth=5, alpha=0.5)\n",
    "    \n",
    "    real_times = np.percentile(dep.df[dep.df['unit_type'] == unit_type]['extended_data.response_duration'],q)\n",
    "    plt.plot(real_times,q,color='orangered',linewidth=5, alpha=0.5)\n",
    "\n",
    "    plt.legend(['Monte-Carlo result', 'Actual data'])\n",
    "    plt.xlabel('Response time (sec)')\n",
    "    plt.ylabel('Percentile')\n",
    "    plt.title(unit_type +' unit responses')\n",
    "    \n",
    "plt.savefig(figloc+'mccomp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a plot to validate the assumption that travel times for trucks and engines are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.arange(100)\n",
    "truck_stations = ['111','115','116']\n",
    "plt.rcParams['figure.figsize'] = [15,5]\n",
    "fig = plt.figure()\n",
    "for i,station_num in enumerate(truck_stations):\n",
    "    engine = dep.station_dict[station_num].sent_full['Engine']\n",
    "    truck = dep.station_dict[station_num].sent_full['Truck/Aerial']\n",
    "    ax = fig.add_subplot(1,3,i+1)\n",
    "    ax.plot(np.percentile(engine,q),q, color='dodgerblue', label='Engine', linewidth=3)\n",
    "    ax.plot(np.percentile(truck,q),q, color='orangered', label='Truck', linewidth=3)\n",
    "    ax.set_xlabel('Travel time (sec)')\n",
    "    ax.set_ylabel('Percentile')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center right')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = dep.station_dict['111'].sent_full['Engine']\n",
    "not_sent = dep.station_dict['111'].not_sent_full['Engine']\n",
    "q = np.arange(100)\n",
    "\n",
    "plt.plot(np.percentile(sent,q),q)\n",
    "plt.plot(np.percentile(not_sent,q),q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a cdf to compare times\n",
    "unit_type = 'ALS'\n",
    "idx = np.argsort(dep.times[unit_type])\n",
    "times = dep.times[unit_type][idx]\n",
    "probs = dep.probs[unit_type][idx]\n",
    "cum_prob = np.cumsum(probs)\n",
    "plt.plot(times,cum_prob)\n",
    "\n",
    "q = np.arange(100)\n",
    "quantiles = np.percentile(dep.df[dep.df['unit_type'] == unit_type]['extended_data.response_duration'],q)\n",
    "\n",
    "\n",
    "plt.plot(quantiles,q/100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
